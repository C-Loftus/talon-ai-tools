# This is an example settings file.
# To make changes, copy this into your user directory and remove the .example extension

settings():
    # user.model_temperature = 0.6

    # Works with any API with the same schema as OpenAI's (i.e. Azure, llamafiles, etc.)
    # user.model_endpoint = "https://api.openai.com/v1/chat/completions"

    # Alternatively, use the llm CLI (see https://github.com/simonw/llm)
    # user.model_endpoint = "llm"
    # If the llm binary is not found on Talon's PATH, you can specify it directly:
    # user.model_llm_path = "/path/to/llm"

    # user.model_system_prompt = "You are an assistant helping an office worker to be more productive."

    # Change to 'gpt-4' or the model of your choice
    # user.openai_model = 'gpt-3.5-turbo'

    # Increase the window width.
    # user.model_window_char_width = 120

# Only uncomment the line below if you want experimental behavior to parse Talon files
# tag(): user.gpt_beta

# Use codeium instead of Github Copilot
# tag(): user.codeium
